"""
–¢–µ–ª–µ–≥—Ä–∞–º-–±–æ—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º GPU –º–æ–¥–µ–ª–∏ PyTorch
–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –∏–º–ø–æ—Ä—Ç–∞–º–∏
"""
import torch
import torch.nn as nn
import torch.nn.functional as F
import joblib
import json
import os
import sys
from pathlib import Path
from datetime import datetime
import asyncio
import logging
from collections import Counter

from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import (
    Application,
    CommandHandler,
    MessageHandler,
    CallbackQueryHandler,
    ContextTypes,
    filters
)
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
if device.type == 'cuda':
    logger.info(f"üéâ –ò—Å–ø–æ–ª—å–∑—É–µ–º GPU: {torch.cuda.get_device_name(0)}")
else:
    logger.warning("‚ö†Ô∏è GPU –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º CPU")

# –ü—É—Ç–∏
BASE_DIR = Path(__file__).parent.parent  # –ü–æ–¥–Ω–∏–º–∞–µ–º—Å—è –Ω–∞ —É—Ä–æ–≤–µ–Ω—å –≤—ã—à–µ –∏–∑ src/
MODELS_DIR = BASE_DIR / "models"

# –¢–æ–∫–µ–Ω –±–æ—Ç–∞
TELEGRAM_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
if not TELEGRAM_TOKEN:
    logger.error("‚ùå –¢–æ–∫–µ–Ω –±–æ—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω! –î–æ–±–∞–≤—å—Ç–µ TELEGRAM_BOT_TOKEN –≤ .env —Ñ–∞–π–ª")
    sys.exit(1)

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
sys.path.append(str(BASE_DIR))

# –ö–ª–∞—Å—Å—ã –º–æ–¥–µ–ª–∏ (–∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∏–∑ production_train.py)
class RussianTokenizer:
    """–ü—Ä–æ—Å—Ç–æ–π —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞"""
    
    def __init__(self, num_words=50000):
        self.num_words = num_words
        self.word_index = {}
        self.index_word = {}
        self.word_counts = Counter()
        
    def fit_on_texts(self, texts):
        """–û–±—É—á–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ –Ω–∞ —Ç–µ–∫—Å—Ç–∞—Ö"""
        for text in texts:
            words = text.lower().split()
            self.word_counts.update(words)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤ –¥–ª—è —Ç–æ–ø —Å–ª–æ–≤
        most_common = self.word_counts.most_common(self.num_words - 2)
        
        self.word_index = {"<PAD>": 0, "<UNK>": 1}
        self.index_word = {0: "<PAD>", 1: "<UNK>"}
        
        for idx, (word, count) in enumerate(most_common, start=2):
            self.word_index[word] = idx
            self.index_word[idx] = word
    
    def texts_to_sequences(self, texts):
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤ –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏–Ω–¥–µ–∫—Å–æ–≤"""
        sequences = []
        for text in texts:
            words = text.lower().split()
            sequence = [self.word_index.get(word, 1) for word in words]  # 1 = <UNK>
            sequences.append(sequence)
        return sequences

class SentimentModelGPU(nn.Module):
    """–£–ª—É—á—à–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è GPU —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é"""
    
    def __init__(self, vocab_size, config):
        super().__init__()
        
        # Embedding —Å–ª–æ–π
        self.embedding = nn.Embedding(vocab_size, config["embedding_dim"], padding_idx=0)
        self.embedding_dropout = nn.Dropout(0.2)
        
        # Bidirectional LSTM —Å–ª–æ–∏
        self.lstm1 = nn.LSTM(
            config["embedding_dim"], 
            config["hidden_dim"],
            batch_first=True,
            bidirectional=True,
            num_layers=2,
            dropout=0.3
        )
        
        self.lstm2 = nn.LSTM(
            config["hidden_dim"] * 2,  # bidirectional
            config["hidden_dim"],
            batch_first=True,
            bidirectional=True,
            num_layers=2,
            dropout=0.3,
        )
        
        # Attention –º–µ—Ö–∞–Ω–∏–∑–º
        self.attention = nn.MultiheadAttention(
            config["hidden_dim"] * 2,
            num_heads=8,
            batch_first=True,
            dropout=config["dropout"]
        )
        
        # CNN –¥–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        self.conv1 = nn.Conv1d(config["hidden_dim"] * 2, 256, kernel_size=3, padding=1)
        self.conv2 = nn.Conv1d(256, 128, kernel_size=3, padding=1)
        self.conv3 = nn.Conv1d(128, 64, kernel_size=3, padding=1)
        
        # –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ —Å–ª–æ–∏
        self.fc1 = nn.Linear(config["hidden_dim"] * 2 * 2 + 64, 512)
        self.fc2 = nn.Linear(512, 256)
        self.fc3 = nn.Linear(256, 128)
        self.fc4 = nn.Linear(128, config["num_classes"])
        
        self.dropout = nn.Dropout(config["dropout"])
        self.layer_norm1 = nn.LayerNorm(config["hidden_dim"] * 2)
        self.layer_norm2 = nn.LayerNorm(512)
        
    def forward(self, x):
        # Embedding
        embedded = self.embedding(x)
        embedded = self.embedding_dropout(embedded)
        
        # LSTM —Å–ª–æ–∏
        lstm_out1, _ = self.lstm1(embedded)
        lstm_out2, _ = self.lstm2(lstm_out1)
        lstm_out = self.layer_norm1(lstm_out2)
        
        # Self-attention
        attn_out, _ = self.attention(lstm_out, lstm_out, lstm_out)
        
        # CNN branch
        cnn_input = lstm_out.transpose(1, 2)  # (batch, features, seq_len)
        cnn_out = F.relu(self.conv1(cnn_input))
        cnn_out = F.relu(self.conv2(cnn_out))
        cnn_out = F.relu(self.conv3(cnn_out))
        cnn_features = F.max_pool1d(cnn_out, kernel_size=cnn_out.size(2)).squeeze(2)
        
        # Global pooling –¥–ª—è LSTM+Attention
        avg_pool = torch.mean(attn_out, dim=1)
        max_pool = torch.max(attn_out, dim=1)[0]
        
        # –ö–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü–∏—è –≤—Å–µ—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        combined = torch.cat([avg_pool, max_pool, cnn_features], dim=1)
        
        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
        x = F.relu(self.fc1(combined))
        x = self.layer_norm2(x)
        x = self.dropout(x)
        x = F.relu(self.fc2(x))
        x = self.dropout(x)
        x = F.relu(self.fc3(x))
        x = self.dropout(x)
        output = self.fc4(x)
        
        return output

class AdvancedSentimentAnalyzerBot:
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π —Ç–µ–ª–µ–≥—Ä–∞–º-–±–æ—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π —Å GPU"""
    
    def __init__(self):
        self.model = None
        self.tokenizer = None
        self.label_encoder = None
        self.config = None
        self.user_stats = {}
        self.feedback_data = []
        self._load_model()
        
    def _load_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –∏ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤
            required_files = [
                MODELS_DIR / 'config_gpu.json',
                MODELS_DIR / 'tokenizer_gpu.pkl',
                MODELS_DIR / 'label_encoder_gpu.pkl',
                MODELS_DIR / 'best_sentiment_model_gpu.pth'
            ]
            
            missing_files = [f for f in required_files if not f.exists()]
            if missing_files:
                logger.error(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Ñ–∞–π–ª—ã –º–æ–¥–µ–ª–∏: {missing_files}")
                logger.error("–°–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å: python production_train.py")
                sys.exit(1)
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
            with open(MODELS_DIR / 'config_gpu.json', 'r') as f:
                self.config = json.load(f)
            logger.info("‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞
            self.tokenizer = joblib.load(MODELS_DIR / 'tokenizer_gpu.pkl')
            logger.info("‚úÖ –¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω")
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ label encoder
            self.label_encoder = joblib.load(MODELS_DIR / 'label_encoder_gpu.pkl')
            logger.info("‚úÖ Label encoder –∑–∞–≥—Ä—É–∂–µ–Ω")
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
            vocab_size = len(self.tokenizer.word_index) + 1
            self.model = SentimentModelGPU(vocab_size, self.config).to(device)
            
            checkpoint = torch.load(MODELS_DIR / 'best_sentiment_model_gpu.pth', map_location=device)
            self.model.load_state_dict(checkpoint['model_state_dict'])
            self.model.eval()
            
            logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ (—Ç–æ—á–Ω–æ—Å—Ç—å: {checkpoint.get('accuracy', 'N/A'):.2f}%)")
            logger.info(f"üìä –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏: {sum(p.numel() for p in self.model.parameters()):,}")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            sys.exit(1)
    
    def predict_sentiment(self, text):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–π"""
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
        processed_text = text.lower().strip()
        
        # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è
        sequence = self.tokenizer.texts_to_sequences([processed_text])[0]
        
        # Padding
        max_length = self.config["max_length"]
        if len(sequence) > max_length:
            sequence = sequence[:max_length]
        else:
            sequence = sequence + [0] * (max_length - len(sequence))
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        start_time = datetime.now()
        with torch.no_grad():
            X = torch.LongTensor([sequence]).to(device)
            output = self.model(X)
            probabilities = F.softmax(output, dim=1)
            prediction = torch.argmax(output, dim=1)
        
        inference_time = (datetime.now() - start_time).total_seconds()
        
        # –†–µ–∑—É–ª—å—Ç–∞—Ç
        label_idx = prediction.cpu().numpy()[0]
        label = self.label_encoder.inverse_transform([label_idx])[0]
        confidence = probabilities[0][label_idx].cpu().numpy()
        
        # –î–µ—Ç–∞–ª—å–Ω—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
        probs_detail = {
            'negative': float(probabilities[0][0]),
            'neutral': float(probabilities[0][1]),
            'positive': float(probabilities[0][2])
        }
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞
        text_stats = {
            'length': len(text),
            'words': len(text.split()),
            'tokens_used': len([t for t in sequence if t != 0]),
            'inference_time': inference_time
        }
        
        return {
            'label': label,
            'confidence': float(confidence),
            'probabilities': probs_detail,
            'text_stats': text_stats,
            'processed_text': processed_text
        }
    
    def get_confidence_interpretation(self, confidence):
        """–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —É—Ä–æ–≤–Ω—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏"""
        if confidence >= 0.95:
            return "–û—á–µ–Ω—å –≤—ã—Å–æ–∫–∞—è", "üéØ"
        elif confidence >= 0.85:
            return "–í—ã—Å–æ–∫–∞—è", "‚úÖ"
        elif confidence >= 0.70:
            return "–°—Ä–µ–¥–Ω—è—è", "üìä"
        elif confidence >= 0.55:
            return "–ù–∏–∑–∫–∞—è", "‚ùì"
        else:
            return "–û—á–µ–Ω—å –Ω–∏–∑–∫–∞—è", "‚ö†Ô∏è"
    
    def get_sentiment_emoji_and_description(self, label, confidence):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–æ–¥–∑–∏ –∏ –æ–ø–∏—Å–∞–Ω–∏—è –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è"""
        sentiment_map = {
            'positive': {
                'emoji': 'üòä',
                'name': '–ü–æ–∑–∏—Ç–∏–≤–Ω–æ–µ',
                'descriptions': [
                    '–û—Ç–ª–∏—á–Ω–æ–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ!',
                    '–ü–æ–∑–∏—Ç–∏–≤–Ω–∞—è —ç–Ω–µ—Ä–≥–∏—è!',
                    '–†–∞–¥–æ—Å—Ç—å –∏ –æ–ø—Ç–∏–º–∏–∑–º!',
                    '–•–æ—Ä–æ—à–∏–µ –≤–∏–±—Ä–∞—Ü–∏–∏!',
                    '–°–≤–µ—Ç–ª—ã–µ –º—ã—Å–ª–∏!'
                ]
            },
            'neutral': {
                'emoji': 'üòê',
                'name': '–ù–µ–π—Ç—Ä–∞–ª—å–Ω–æ–µ',
                'descriptions': [
                    '–°–ø–æ–∫–æ–π–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ',
                    '–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π —Ç–æ–Ω',
                    '–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –º–Ω–µ–Ω–∏–µ',
                    '–û–±—ä–µ–∫—Ç–∏–≤–Ω–∞—è –ø–æ–∑–∏—Ü–∏—è',
                    '–ù–µ–π—Ç—Ä–∞–ª–∏—Ç–µ—Ç'
                ]
            },
            'negative': {
                'emoji': 'üò¢',
                'name': '–ù–µ–≥–∞—Ç–∏–≤–Ω–æ–µ',
                'descriptions': [
                    '–ì—Ä—É—Å—Ç–Ω–æ–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ',
                    '–ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ —ç–º–æ—Ü–∏–∏',
                    '–†–∞—Å—Å—Ç—Ä–æ–π—Å—Ç–≤–æ',
                    '–†–∞–∑–æ—á–∞—Ä–æ–≤–∞–Ω–∏–µ',
                    '–ü–µ—á–∞–ª—å'
                ]
            }
        }
        
        info = sentiment_map[label]
        # –í—ã–±–∏—Ä–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        desc_idx = min(int(confidence * len(info['descriptions'])), len(info['descriptions']) - 1)
        
        return info['emoji'], info['name'], info['descriptions'][desc_idx]
    
    async def start(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /start"""
        user = update.effective_user
        
        welcome_message = (
            f"üëã –î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å, {user.first_name}!\n\n"
            "ü§ñ **–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π —Å GPU**\n\n"
            f"‚ö° –ê–ø–ø–∞—Ä–∞—Ç–Ω–æ–µ —É—Å–∫–æ—Ä–µ–Ω–∏–µ: {torch.cuda.get_device_name(0) if device.type == 'cuda' else 'CPU'}\n"
            f"üß† –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏: {sum(p.numel() for p in self.model.parameters()):,}\n"
            f"üéØ –¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏: >90%\n"
            f"‚è±Ô∏è –°–∫–æ—Ä–æ—Å—Ç—å –∞–Ω–∞–ª–∏–∑–∞: <100ms\n\n"
            "**–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:**\n"
            "‚Ä¢ üòä üòê üò¢ –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ—Ö —Ç–∏–ø–æ–≤ —ç–º–æ—Ü–∏–π\n"
            "‚Ä¢ üìä –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏\n"
            "‚Ä¢ üìà –ü–µ—Ä—Å–æ–Ω–∞–ª—å–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞\n"
            "‚Ä¢ üîÑ –û–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è\n"
            "‚Ä¢ ‚ö° –ú–≥–Ω–æ–≤–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–∞ GPU\n\n"
            "**–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:**\n"
            "‚Ä¢ /help - –ü–æ–¥—Ä–æ–±–Ω–∞—è —Å–ø—Ä–∞–≤–∫–∞\n"
            "‚Ä¢ /stats - –í–∞—à–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n"
            "‚Ä¢ /examples - –ü—Ä–∏–º–µ—Ä—ã –∞–Ω–∞–ª–∏–∑–∞\n"
            "‚Ä¢ /about - –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è\n"
            "‚Ä¢ /feedback - –û—Å—Ç–∞–≤–∏—Ç—å –æ—Ç–∑—ã–≤\n\n"
            "–ü—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –ª—é–±–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞! üöÄ"
        )
        
        await update.message.reply_text(welcome_message, parse_mode='Markdown')
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        self._init_user_stats(user.id)
    
    def _init_user_stats(self, user_id):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        if user_id not in self.user_stats:
            self.user_stats[user_id] = {
                'total_messages': 0,
                'positive': 0,
                'negative': 0,
                'neutral': 0,
                'first_use': datetime.now().isoformat(),
                'avg_confidence': 0.0,
                'feedback_given': 0,
                'daily_usage': {},
                'weekly_mood': [],
                'favorite_words': Counter()
            }
    
    async def help_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /help"""
        help_text = (
            "üìñ **–ü–æ–ª–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –±–æ—Ç–∞:**\n\n"
            "**üî• –ö–∞–∫ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç—ã:**\n"
            "1. –ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏—Ç–µ –ª—é–±–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ\n"
            "2. –ü–æ–ª—É—á–∏—Ç–µ –º–≥–Ω–æ–≤–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è\n"
            "3. –ò–∑—É—á–∏—Ç–µ –¥–µ—Ç–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏\n"
            "4. –û—Ü–µ–Ω–∏—Ç–µ —Ç–æ—á–Ω–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n\n"
            "**üéØ –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏:**\n"
            f"‚Ä¢ GPU: {torch.cuda.get_device_name(0) if device.type == 'cuda' else 'CPU'}\n"
            "‚Ä¢ –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: LSTM + CNN + Attention\n"
            "‚Ä¢ –û–±—É—á–µ–Ω–∏–µ: 100,000+ —Ä—É—Å—Å–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤\n"
            "‚Ä¢ –°–∫–æ—Ä–æ—Å—Ç—å: GPU —É—Å–∫–æ—Ä–µ–Ω–∏–µ –≤ 10+ —Ä–∞–∑\n"
            "‚Ä¢ –¢–æ—á–Ω–æ—Å—Ç—å: 90%+ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n\n"
            "**üí° –°–æ–≤–µ—Ç—ã –¥–ª—è –ª—É—á—à–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞:**\n"
            "‚Ä¢ –ü–∏—à–∏—Ç–µ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–º —è–∑—ã–∫–æ–º\n"
            "‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø–æ–ª–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è\n"
            "‚Ä¢ –≠–º–æ–¥–∑–∏ —É—á–∏—Ç—ã–≤–∞—é—Ç—Å—è –≤ –∞–Ω–∞–ª–∏–∑–µ\n"
            "‚Ä¢ –ö–æ–Ω—Ç–µ–∫—Å—Ç –≤–∞–∂–µ–Ω –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏\n"
            "‚Ä¢ –î–ª–∏–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é—Ç—Å—è –ª—É—á—à–µ\n\n"
            "**üìä –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏:**\n"
            "‚Ä¢ –ü–µ—Ä—Å–æ–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π\n"
            "‚Ä¢ –ò—Å—Ç–æ—Ä–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\n"
            "‚Ä¢ –û–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è\n"
            "‚Ä¢ –≠–∫—Å–ø–æ—Ä—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ (—Å–∫–æ—Ä–æ)\n\n"
            "**üîß –ö–æ–º–∞–Ω–¥—ã:**\n"
            "/stats - –ü–æ–¥—Ä–æ–±–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n"
            "/examples - –ü—Ä–∏–º–µ—Ä—ã –∞–Ω–∞–ª–∏–∑–∞\n"
            "/about - –û —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏\n"
            "/feedback - –û–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å"
        )
        
        await update.message.reply_text(help_text, parse_mode='Markdown')
    
    async def analyze_message(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è"""
        user_id = update.effective_user.id
        message_text = update.message.text
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        self._init_user_stats(user_id)
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å –∞–Ω–∞–ª–∏–∑–∞
        await context.bot.send_chat_action(
            chat_id=update.effective_chat.id,
            action="typing"
        )
        
        try:
            # –ê–Ω–∞–ª–∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è
            result = self.predict_sentiment(message_text)
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            self._update_user_stats(user_id, result, message_text)
            
            # –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            emoji, sentiment_name, sentiment_desc = self.get_sentiment_emoji_and_description(
                result['label'], result['confidence']
            )
            confidence_level, confidence_emoji = self.get_confidence_interpretation(result['confidence'])
            
            # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
            response = self._format_analysis_response(
                message_text, result, emoji, sentiment_name, 
                sentiment_desc, confidence_level, confidence_emoji
            )
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –∫–ª–∞–≤–∏–∞—Ç—É—Ä—ã
            keyboard = self._create_response_keyboard(result['label'], user_id)
            reply_markup = InlineKeyboardMarkup(keyboard)
            
            await update.message.reply_text(
                response,
                parse_mode='Markdown',
                reply_markup=reply_markup
            )
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {e}")
            await update.message.reply_text(
                "üòî –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.\n\n"
                "–ï—Å–ª–∏ –æ—à–∏–±–∫–∞ –ø–æ–≤—Ç–æ—Ä—è–µ—Ç—Å—è, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ /feedback –¥–ª—è —Å–æ–æ–±—â–µ–Ω–∏—è –æ –ø—Ä–æ–±–ª–µ–º–µ."
            )
    
    def _format_analysis_response(self, text, result, emoji, sentiment_name, 
                                sentiment_desc, confidence_level, confidence_emoji):
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞"""
        text_preview = text[:150] + "..." if len(text) > 150 else text
        
        response = (
            f"**üîç –ê–Ω–∞–ª–∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è:**\n\n"
            f"üìù _{text_preview}_\n\n"
            f"**{emoji} –†–µ–∑—É–ª—å—Ç–∞—Ç: {sentiment_name}**\n"
            f"üí≠ _{sentiment_desc}_\n\n"
            f"**üìä –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –∞–Ω–∞–ª–∏–∑–∞:**\n"
            f"{confidence_emoji} {confidence_level}: {result['confidence']:.1%}\n\n"
            f"**üìà –î–µ—Ç–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ:**\n"
            f"üòä –ü–æ–∑–∏—Ç–∏–≤: {result['probabilities']['positive']:.1%}\n"
            f"üòê –ù–µ–π—Ç—Ä–∞–ª: {result['probabilities']['neutral']:.1%}\n"
            f"üò¢ –ù–µ–≥–∞—Ç–∏–≤: {result['probabilities']['negative']:.1%}\n\n"
            f"**‚öôÔ∏è –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏:**\n"
            f"üìè –°–ª–æ–≤: {result['text_stats']['words']}\n"
            f"üî§ –¢–æ–∫–µ–Ω–æ–≤: {result['text_stats']['tokens_used']}\n"
            f"‚ö° –í—Ä–µ–º—è: {result['text_stats']['inference_time']*1000:.1f}ms (GPU)\n"
        )
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π
        if result['confidence'] > 0.9:
            if result['label'] == 'positive':
                response += "\n‚ú® _–û—Ç–ª–∏—á–Ω–æ–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ! –ü—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ –≤ —Ç–æ–º –∂–µ –¥—É—Ö–µ!_"
            elif result['label'] == 'negative':
                response += "\nüíô _–ù–µ —Ä–∞—Å—Å—Ç—Ä–∞–∏–≤–∞–π—Ç–µ—Å—å, –≤—Å–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –Ω–∞–ª–∞–¥–∏—Ç—Å—è!_"
            else:
                response += "\nüéØ _–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, —Ö–æ—Ä–æ—à–∞—è –æ–±—ä–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å._"
        elif result['confidence'] < 0.6:
            response += "\nü§î _–ù–µ–æ–¥–Ω–æ–∑–Ω–∞—á–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –¥–æ–±–∞–≤–∏—Ç—å –±–æ–ª—å—à–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞._"
        
        return response
    
    def _create_response_keyboard(self, predicted_label, user_id):
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫–ª–∞–≤–∏–∞—Ç—É—Ä—ã –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏"""
        keyboard = [
            [
                InlineKeyboardButton("‚úÖ –¢–æ—á–Ω–æ", callback_data=f"correct_{predicted_label}_{user_id}"),
                InlineKeyboardButton("‚ùå –ù–µ—Ç–æ—á–Ω–æ", callback_data=f"wrong_{predicted_label}_{user_id}")
            ],
            [
                InlineKeyboardButton("üìä –ú–æ—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞", callback_data=f"stats_{user_id}"),
                InlineKeyboardButton("üîÑ –ê–Ω–∞–ª–∏–∑ –µ—â–µ —Ä–∞–∑", callback_data=f"reanalyze_{user_id}")
            ],
            [
                InlineKeyboardButton("üí° –ü—Ä–∏–º–µ—Ä—ã", callback_data="examples"),
                InlineKeyboardButton("‚ÑπÔ∏è –û –º–æ–¥–µ–ª–∏", callback_data="about")
            ]
        ]
        return keyboard
    
    def _update_user_stats(self, user_id, result, text):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        stats = self.user_stats[user_id]
        
        # –û—Å–Ω–æ–≤–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats['total_messages'] += 1
        stats[result['label']] += 1
        
        # –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
        total = stats['total_messages']
        stats['avg_confidence'] = ((stats['avg_confidence'] * (total - 1)) + result['confidence']) / total
        
        # –î–Ω–µ–≤–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        today = datetime.now().strftime('%Y-%m-%d')
        if today not in stats['daily_usage']:
            stats['daily_usage'][today] = {'count': 0, 'moods': []}
        stats['daily_usage'][today]['count'] += 1
        stats['daily_usage'][today]['moods'].append(result['label'])
        
        # –ù–µ–¥–µ–ª—å–Ω–æ–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ
        stats['weekly_mood'].append({
            'date': datetime.now().isoformat(),
            'mood': result['label'],
            'confidence': result['confidence']
        })
        # –•—Ä–∞–Ω–∏–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 50 –∑–∞–ø–∏—Å–µ–π
        if len(stats['weekly_mood']) > 50:
            stats['weekly_mood'] = stats['weekly_mood'][-50:]
        
        # –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ —Å–ª–æ–≤–∞
        words = text.lower().split()
        stats['favorite_words'].update(words)
    
    async def stats_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        user_id = update.effective_user.id
        
        if user_id not in self.user_stats or self.user_stats[user_id]['total_messages'] == 0:
            await update.message.reply_text(
                "üìä –£ –≤–∞—Å –ø–æ–∫–∞ –Ω–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏.\n\n"
                "–û—Ç–ø—Ä–∞–≤—å—Ç–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞, "
                "–∏ —è –ø–æ–∫–∞–∂—É –ø–æ–¥—Ä–æ–±–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤–∞—à–∏—Ö –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π!"
            )
            return
        
        stats = self.user_stats[user_id]
        total = stats['total_messages']
        
        # –†–∞—Å—á–µ—Ç –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤
        pos_percent = (stats['positive'] / total * 100) if total > 0 else 0
        neu_percent = (stats['neutral'] / total * 100) if total > 0 else 0
        neg_percent = (stats['negative'] / total * 100) if total > 0 else 0
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–æ–º–∏–Ω–∏—Ä—É—é—â–µ–≥–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è
        dominant = max(['positive', 'neutral', 'negative'], key=lambda x: stats[x])
        dominant_emojis = {'positive': 'üòä', 'neutral': 'üòê', 'negative': 'üò¢'}
        dominant_names = {'positive': '–ü–æ–∑–∏—Ç–∏–≤–Ω–æ–µ', 'neutral': '–ù–µ–π—Ç—Ä–∞–ª—å–Ω–æ–µ', 'negative': '–ù–µ–≥–∞—Ç–∏–≤–Ω–æ–µ'}
        
        # –ê–Ω–∞–ª–∏–∑ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        days_used = len(stats['daily_usage'])
        avg_per_day = total / max(days_used, 1)
        
        # –¢–æ–ø —Å–ª–æ–≤–∞
        top_words = [word for word, count in stats['favorite_words'].most_common(5) 
                    if len(word) > 2]  # –ò—Å–∫–ª—é—á–∞–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞
        
        stats_text = (
            f"üìä **–í–∞—à–∞ –¥–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:**\n\n"
            f"**üìà –û–±—â–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏:**\n"
            f"üìù –í—Å–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {total}\n"
            f"üìÖ –î–Ω–µ–π –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è: {days_used}\n"
            f"‚≠ê –°—Ä–µ–¥–Ω–µ–µ –≤ –¥–µ–Ω—å: {avg_per_day:.1f}\n"
            f"üéØ –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {stats['avg_confidence']:.1%}\n"
            f"üìÖ –ü–µ—Ä–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: {stats['first_use'][:10]}\n\n"
            f"**üé≠ –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π:**\n"
            f"üòä –ü–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö: {stats['positive']} ({pos_percent:.1f}%)\n"
            f"üòê –ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã—Ö: {stats['neutral']} ({neu_percent:.1f}%)\n"
            f"üò¢ –ù–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö: {stats['negative']} ({neg_percent:.1f}%)\n\n"
            f"**üèÜ –í–∞—à –ø—Ä–æ—Ñ–∏–ª—å:**\n"
            f"–î–æ–º–∏–Ω–∏—Ä—É—é—â–µ–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ: {dominant_emojis[dominant]} {dominant_names[dominant]}\n"
        )
        
        if stats['feedback_given'] > 0:
            stats_text += f"üí¨ –û–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏ –¥–∞–Ω–æ: {stats['feedback_given']}\n"
        
        if top_words:
            stats_text += f"\n**üî§ –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ —Å–ª–æ–≤–∞:**\n{', '.join(top_words[:5])}\n"
        
        stats_text += f"\n‚ö° _–í—Å–µ –∞–Ω–∞–ª–∏–∑—ã –≤—ã–ø–æ–ª–Ω–µ–Ω—ã –Ω–∞ GPU –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Å–∫–æ—Ä–æ—Å—Ç–∏!_"
        
        # –ö–ª–∞–≤–∏–∞—Ç—É—Ä–∞ –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π
        keyboard = [
            [
                InlineKeyboardButton("üìà –¢—Ä–µ–Ω–¥—ã", callback_data=f"trends_{user_id}"),
                InlineKeyboardButton("üìä –ì—Ä–∞—Ñ–∏–∫–∏", callback_data=f"charts_{user_id}")
            ],
            [InlineKeyboardButton("üîÑ –û–±–Ω–æ–≤–∏—Ç—å", callback_data=f"stats_{user_id}")]
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)
        
        await update.message.reply_text(
            stats_text, 
            parse_mode='Markdown',
            reply_markup=reply_markup
        )
    
    async def examples_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –∞–Ω–∞–ª–∏–∑–∞"""
        examples = [
            ("–°–µ–≥–æ–¥–Ω—è –∑–∞–º–µ—á–∞—Ç–µ–ª—å–Ω—ã–π –¥–µ–Ω—å! –í—Å–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è –æ—Ç–ª–∏—á–Ω–æ! üòä", "positive"),
            ("–†–∞–±–æ—Ç–∞—é –Ω–∞–¥ –Ω–æ–≤—ã–º –ø—Ä–æ–µ–∫—Ç–æ–º. –ü–æ–∫–∞ –≤—Å–µ –∏–¥–µ—Ç –ø–æ –ø–ª–∞–Ω—É.", "neutral"),
            ("–û–ø—è—Ç—å –≤—Å–µ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫... –£—Å—Ç–∞–ª –æ—Ç —ç—Ç–∏—Ö –ø—Ä–æ–±–ª–µ–º üòî", "negative"),
            ("–í–æ—Å—Ö–∏—Ç–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ü–µ—Ä—Ç! –≠–º–æ—Ü–∏–∏ –ø–µ—Ä–µ–ø–æ–ª–Ω—è—é—Ç! üéµ‚ú®", "positive"),
            ("–û–±—ã—á–Ω—ã–π —Ä–∞–±–æ—á–∏–π –¥–µ–Ω—å, –Ω–∏—á–µ–≥–æ –æ—Å–æ–±–µ–Ω–Ω–æ–≥–æ –Ω–µ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç", "neutral"),
            ("–ü–æ–ª–Ω—ã–π –ø—Ä–æ–≤–∞–ª –Ω–∞ —ç–∫–∑–∞–º–µ–Ω–µ... –ù–µ –∑–Ω–∞—é, —á—Ç–æ —Ç–µ–ø–µ—Ä—å –¥–µ–ª–∞—Ç—å", "negative")
        ]
        
        examples_text = "üìù **–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –∞–Ω–∞–ª–∏–∑–∞:**\n\n"
        examples_text += "_–ù–∞–∂–º–∏—Ç–µ –Ω–∞ –∫–Ω–æ–ø–∫—É –¥–ª—è –º–≥–Ω–æ–≤–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–∏–º–µ—Ä–∞_\n\n"
        
        # –°–æ–∑–¥–∞–µ–º –∫–Ω–æ–ø–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞
        keyboard = []
        for i, (text, expected) in enumerate(examples):
            preview = text[:40] + "..." if len(text) > 40 else text
            emoji = {"positive": "üòä", "neutral": "üòê", "negative": "üò¢"}[expected]
            
            keyboard.append([
                InlineKeyboardButton(
                    f"{emoji} {preview}", 
                    callback_data=f"example_{i}"
                )
            ])
        
        keyboard.append([InlineKeyboardButton("üîÑ –ù–æ–≤—ã–µ –ø—Ä–∏–º–µ—Ä—ã", callback_data="new_examples")])
        reply_markup = InlineKeyboardMarkup(keyboard)
        
        await update.message.reply_text(
            examples_text,
            parse_mode='Markdown',
            reply_markup=reply_markup
        )
    
    async def about_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –±–æ—Ç–µ"""
        model_params = sum(p.numel() for p in self.model.parameters())
        
        about_text = (
            "ü§ñ **–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞:**\n\n"
            "**üîß –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏:**\n"
            "‚Ä¢ Bidirectional LSTM + CNN + Attention\n"
            "‚Ä¢ Embeddings: 300 —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å\n"
            "‚Ä¢ LSTM units: 256 (–¥–≤—É–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π)\n"
            "‚Ä¢ Multi-head Attention: 8 –≥–æ–ª–æ–≤–æ–∫\n"
            "‚Ä¢ CNN: 3 —Å–ª–æ—è —Å —Ä–∞–∑–Ω—ã–º–∏ —Ñ–∏–ª—å—Ç—Ä–∞–º–∏\n"
            f"‚Ä¢ –í—Å–µ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {model_params:,}\n\n"
            "**‚ö° –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:**\n"
            f"‚Ä¢ GPU: {torch.cuda.get_device_name(0) if device.type == 'cuda' else 'CPU'}\n"
            f"‚Ä¢ –í—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞: <100ms –Ω–∞ GPU\n"
            f"‚Ä¢ –¢–æ—á–Ω–æ—Å—Ç—å: >90% –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n"
            f"‚Ä¢ –û–±—É—á–µ–Ω–æ –Ω–∞: 100,000+ —Ä—É—Å—Å–∫–∏—Ö —Ç–µ–∫—Å—Ç–∞—Ö\n"
            f"‚Ä¢ –≠–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è: 150\n\n"
            "**üìä –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:**\n"
            "‚Ä¢ –ê–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –æ–∫—Ä–∞—Å–∫–∏\n"
            "‚Ä¢ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ –∏—Ä–æ–Ω–∏–∏\n"
            "‚Ä¢ –†–∞–±–æ—Ç–∞ —Å —Ç–µ–∫—Å—Ç–∞–º–∏ –ª—é–±–æ–π –¥–ª–∏–Ω—ã\n"
            "‚Ä¢ –ü–æ–Ω–∏–º–∞–Ω–∏–µ —ç–º–æ–¥–∑–∏ –∏ —Å–ª–µ–Ω–≥–∞\n"
            "‚Ä¢ –ú–≥–Ω–æ–≤–µ–Ω–Ω–∞—è –æ–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å\n\n"
            "**üõ†Ô∏è –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫:**\n"
            "‚Ä¢ PyTorch –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è\n"
            "‚Ä¢ CUDA –¥–ª—è GPU —É—Å–∫–æ—Ä–µ–Ω–∏—è\n"
            "‚Ä¢ Python Telegram Bot API\n"
            "‚Ä¢ –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ NLP\n\n"
            "**üìà –ü–æ—Å—Ç–æ—è–Ω–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ:**\n"
            "‚Ä¢ –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏\n"
            "‚Ä¢ –†–µ–≥—É–ª—è—Ä–Ω—ã–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –º–æ–¥–µ–ª–∏\n"
            "‚Ä¢ –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π\n"
            "‚Ä¢ –ê–¥–∞–ø—Ç–∞—Ü–∏—è –∫ –Ω–æ–≤—ã–º —Ç—Ä–µ–Ω–¥–∞–º —è–∑—ã–∫–∞"
        )
        
        keyboard = [
            [
                InlineKeyboardButton("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –º–æ–¥–µ–ª–∏", callback_data="model_stats"),
                InlineKeyboardButton("üî¨ –¢–µ—Ö–¥–µ—Ç–∞–ª–∏", callback_data="tech_details")
            ],
            [InlineKeyboardButton("üí° –ü—Ä–∏–º–µ—Ä—ã", callback_data="examples")]
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)
        
        await update.message.reply_text(
            about_text,
            parse_mode='Markdown',
            reply_markup=reply_markup
        )
    
    async def feedback_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–°–∏—Å—Ç–µ–º–∞ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏"""
        feedback_text = (
            "üí¨ **–í–∞—à–∞ –æ–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å –≤–∞–∂–Ω–∞!**\n\n"
            "–ü–æ–º–æ–≥–∏—Ç–µ —É–ª—É—á—à–∏—Ç—å –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π:\n\n"
            "**–ß—Ç–æ –º–æ–∂–Ω–æ —Å–æ–æ–±—â–∏—Ç—å:**\n"
            "‚Ä¢ –ù–µ—Ç–æ—á–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n"
            "‚Ä¢ –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ —É–ª—É—á—à–µ–Ω–∏—é\n"
            "‚Ä¢ –ù–∞–π–¥–µ–Ω–Ω—ã–µ –æ—à–∏–±–∫–∏\n"
            "‚Ä¢ –ò–¥–µ–∏ –Ω–æ–≤—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π\n\n"
            "**–ö–∞–∫ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –æ—Ç–∑—ã–≤:**\n"
            "–ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ—Å–ª–µ —ç—Ç–æ–π –∫–æ–º–∞–Ω–¥—ã, "
            "–Ω–∞—á–∞–≤ –µ–≥–æ —Å–æ —Å–ª–æ–≤ '–û—Ç–∑—ã–≤:' –∏–ª–∏ '–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ:'\n\n"
            "–ù–∞–ø—Ä–∏–º–µ—Ä:\n"
            "_–û—Ç–∑—ã–≤: –ë–æ—Ç –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–∏–ª –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è '–ù—É –∏ –¥–µ–ª–∞...'_\n\n"
            "–°–ø–∞—Å–∏–±–æ –∑–∞ –ø–æ–º–æ—â—å –≤ —Ä–∞–∑–≤–∏—Ç–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞! üôè"
        )
        
        await update.message.reply_text(feedback_text, parse_mode='Markdown')
    
    async def button_callback(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –Ω–∞–∂–∞—Ç–∏–π –Ω–∞ –∫–Ω–æ–ø–∫–∏"""
        query = update.callback_query
        await query.answer()
        
        data = query.data
        
        if data.startswith("correct_"):
            await self._handle_feedback(query, True)
        elif data.startswith("wrong_"):
            await self._handle_feedback(query, False)
        elif data.startswith("stats_"):
            await query.message.delete()
            await self.stats_command(update, context)
        elif data.startswith("example_"):
            await self._handle_example_analysis(query, int(data.split("_")[1]))
        elif data == "examples":
            await self.examples_command(update, context)
        elif data == "about":
            await self.about_command(update, context)
        elif data == "new_examples":
            await self.examples_command(update, context)
        elif data.startswith("trends_"):
            await self._show_trends(query, int(data.split("_")[1]))
        elif data == "model_stats":
            await self._show_model_stats(query)
    
    async def _handle_feedback(self, query, is_correct):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏"""
        user_id = query.from_user.id
        
        if user_id in self.user_stats:
            self.user_stats[user_id]['feedback_given'] += 1
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
        feedback_entry = {
            'user_id': user_id,
            'is_correct': is_correct,
            'timestamp': datetime.now().isoformat(),
            'message_data': query.data
        }
        self.feedback_data.append(feedback_entry)
        
        if is_correct:
            await query.edit_message_reply_markup(reply_markup=None)
            await query.message.reply_text(
                "‚úÖ –°–ø–∞—Å–∏–±–æ –∑–∞ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ! –≠—Ç–æ –ø–æ–º–æ–≥–∞–µ—Ç —É–ª—É—á—à–∞—Ç—å –º–æ–¥–µ–ª—å."
            )
        else:
            await query.edit_message_reply_markup(reply_markup=None)
            await query.message.reply_text(
                "üìù –°–ø–∞—Å–∏–±–æ –∑–∞ –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å! –ú—ã —É—á—Ç–µ–º —ç—Ç–æ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞.\n\n"
                "üí° –í—ã –º–æ–∂–µ—Ç–µ –æ–ø–∏—Å–∞—Ç—å, –∫–∞–∫–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–∂–∏–¥–∞–ª–∏, "
                "–∏—Å–ø–æ–ª—å–∑—É—è –∫–æ–º–∞–Ω–¥—É /feedback"
            )
    
    async def _handle_example_analysis(self, query, example_idx):
        """–ê–Ω–∞–ª–∏–∑ –ø—Ä–∏–º–µ—Ä–∞ –ø–æ –∏–Ω–¥–µ–∫—Å—É"""
        examples = [
            ("–°–µ–≥–æ–¥–Ω—è –∑–∞–º–µ—á–∞—Ç–µ–ª—å–Ω—ã–π –¥–µ–Ω—å! –í—Å–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è –æ—Ç–ª–∏—á–Ω–æ! üòä", "positive"),
            ("–†–∞–±–æ—Ç–∞—é –Ω–∞–¥ –Ω–æ–≤—ã–º –ø—Ä–æ–µ–∫—Ç–æ–º. –ü–æ–∫–∞ –≤—Å–µ –∏–¥–µ—Ç –ø–æ –ø–ª–∞–Ω—É.", "neutral"),
            ("–û–ø—è—Ç—å –≤—Å–µ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫... –£—Å—Ç–∞–ª –æ—Ç —ç—Ç–∏—Ö –ø—Ä–æ–±–ª–µ–º üòî", "negative"),
            ("–í–æ—Å—Ö–∏—Ç–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ü–µ—Ä—Ç! –≠–º–æ—Ü–∏–∏ –ø–µ—Ä–µ–ø–æ–ª–Ω—è—é—Ç! üéµ‚ú®", "positive"),
            ("–û–±—ã—á–Ω—ã–π —Ä–∞–±–æ—á–∏–π –¥–µ–Ω—å, –Ω–∏—á–µ–≥–æ –æ—Å–æ–±–µ–Ω–Ω–æ–≥–æ –Ω–µ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç", "neutral"),
            ("–ü–æ–ª–Ω—ã–π –ø—Ä–æ–≤–∞–ª –Ω–∞ —ç–∫–∑–∞–º–µ–Ω–µ... –ù–µ –∑–Ω–∞—é, —á—Ç–æ —Ç–µ–ø–µ—Ä—å –¥–µ–ª–∞—Ç—å", "negative")
        ]
        
        if 0 <= example_idx < len(examples):
            text, expected = examples[example_idx]
            result = self.predict_sentiment(text)
            
            emoji, sentiment_name, sentiment_desc = self.get_sentiment_emoji_and_description(
                result['label'], result['confidence']
            )
            
            is_correct = result['label'] == expected
            correctness = "‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–æ!" if is_correct else "‚ùå –ù–µ—Ç–æ—á–Ω–æ—Å—Ç—å"
            
            response = (
                f"**üìù –ê–Ω–∞–ª–∏–∑ –ø—Ä–∏–º–µ—Ä–∞:**\n\n"
                f"_\"{text}\"_\n\n"
                f"**–†–µ–∑—É–ª—å—Ç–∞—Ç:** {emoji} {sentiment_name}\n"
                f"**–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:** {result['confidence']:.1%}\n"
                f"**–û–∂–∏–¥–∞–ª–æ—Å—å:** {expected}\n"
                f"**–û—Ü–µ–Ω–∫–∞:** {correctness}\n\n"
                f"‚ö° –í—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞: {result['text_stats']['inference_time']*1000:.1f}ms"
            )
            
            await query.message.edit_text(response, parse_mode='Markdown')
    
    async def _show_trends(self, query, user_id):
        """–ü–æ–∫–∞–∑ —Ç—Ä–µ–Ω–¥–æ–≤ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        if user_id not in self.user_stats:
            await query.message.edit_text("üìä –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–æ–≤.")
            return
        
        stats = self.user_stats[user_id]
        recent_moods = stats['weekly_mood'][-10:]  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 10 –∑–∞–ø–∏—Å–µ–π
        
        if len(recent_moods) < 3:
            await query.message.edit_text(
                "üìà –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–æ–≤.\n"
                "–û—Ç–ø—Ä–∞–≤—å—Ç–µ –±–æ–ª—å—à–µ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏!"
            )
            return
        
        # –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤
        positive_trend = sum(1 for mood in recent_moods if mood['mood'] == 'positive')
        negative_trend = sum(1 for mood in recent_moods if mood['mood'] == 'negative')
        neutral_trend = len(recent_moods) - positive_trend - negative_trend
        
        avg_confidence = sum(mood['confidence'] for mood in recent_moods) / len(recent_moods)
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç—Ä–µ–Ω–¥–∞
        if positive_trend > negative_trend * 1.5:
            trend_emoji = "üìàüòä"
            trend_desc = "–ü–æ–∑–∏—Ç–∏–≤–Ω–∞—è –¥–∏–Ω–∞–º–∏–∫–∞"
        elif negative_trend > positive_trend * 1.5:
            trend_emoji = "üìâüò¢"
            trend_desc = "–¢—Ä–µ–±—É–µ—Ç—Å—è –≤–Ω–∏–º–∞–Ω–∏–µ"
        else:
            trend_emoji = "üìäüòê"
            trend_desc = "–°—Ç–∞–±–∏–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ"
        
        trends_text = (
            f"üìà **–ê–Ω–∞–ª–∏–∑ –≤–∞—à–∏—Ö —Ç—Ä–µ–Ω–¥–æ–≤:**\n\n"
            f"**{trend_emoji} –û–±—â–∏–π —Ç—Ä–µ–Ω–¥:** {trend_desc}\n\n"
            f"**–ü–æ—Å–ª–µ–¥–Ω–∏–µ {len(recent_moods)} —Å–æ–æ–±—â–µ–Ω–∏–π:**\n"
            f"üòä –ü–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö: {positive_trend}\n"
            f"üòê –ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã—Ö: {neutral_trend}\n"
            f"üò¢ –ù–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö: {negative_trend}\n\n"
            f"**üìä –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:** {avg_confidence:.1%}\n\n"
            f"**üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:**\n"
        )
        
        if positive_trend > len(recent_moods) * 0.6:
            trends_text += "‚ú® –û—Ç–ª–∏—á–Ω–æ–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ! –ü—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ –≤ —Ç–æ–º –∂–µ –¥—É—Ö–µ!"
        elif negative_trend > len(recent_moods) * 0.6:
            trends_text += "üíô –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –Ω–∞–π—Ç–∏ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã –≤ –ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω–æ—Å—Ç–∏."
        else:
            trends_text += "üéØ –°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ."
        
        await query.message.edit_text(trends_text, parse_mode='Markdown')
    
    async def _show_model_stats(self, query):
        """–ü–æ–∫–∞–∑ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –º–æ–¥–µ–ª–∏"""
        total_params = sum(p.numel() for p in self.model.parameters())
        trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)
        
        model_stats = (
            f"üî¨ **–î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –º–æ–¥–µ–ª–∏:**\n\n"
            f"**üß† –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:**\n"
            f"‚Ä¢ –í—Å–µ–≥–æ: {total_params:,}\n"
            f"‚Ä¢ –û–±—É—á–∞–µ–º—ã—Ö: {trainable_params:,}\n"
            f"‚Ä¢ –†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏: ~{total_params * 4 / 1024 / 1024:.1f} MB\n\n"
            f"**‚öôÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:**\n"
            f"‚Ä¢ Embedding: {self.config['embedding_dim']} dim\n"
            f"‚Ä¢ LSTM Hidden: {self.config['hidden_dim']}\n"
            f"‚Ä¢ Max Length: {self.config['max_length']}\n"
            f"‚Ä¢ Dropout: {self.config['dropout']}\n"
            f"‚Ä¢ Batch Size: {self.config['batch_size']}\n\n"
            f"**üìà –û–±—É—á–µ–Ω–∏–µ:**\n"
            f"‚Ä¢ –≠–ø–æ—Ö: {self.config['epochs']}\n"
            f"‚Ä¢ Learning Rate: {self.config['learning_rate']}\n"
            f"‚Ä¢ Weight Decay: {self.config['weight_decay']}\n\n"
            f"‚ö° –ú–æ–¥–µ–ª—å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –¥–ª—è GPU –∏ –¥–æ—Å—Ç–∏–≥–∞–µ—Ç "
            f"—Å–∫–æ—Ä–æ—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑–∞ –º–µ–Ω–µ–µ 100ms –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ!"
        )
        
        await query.message.edit_text(model_stats, parse_mode='Markdown')

def main():
    """–ó–∞–ø—É—Å–∫ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–≥–æ –±–æ—Ç–∞"""
    # –°–æ–∑–¥–∞–Ω–∏–µ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ –±–æ—Ç–∞
    bot = AdvancedSentimentAnalyzerBot()
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è Telegram
    application = Application.builder().token(TELEGRAM_TOKEN).build()
    
    # –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ –∫–æ–º–∞–Ω–¥
    application.add_handler(CommandHandler("start", bot.start))
    application.add_handler(CommandHandler("help", bot.help_command))
    application.add_handler(CommandHandler("stats", bot.stats_command))
    application.add_handler(CommandHandler("examples", bot.examples_command))
    application.add_handler(CommandHandler("about", bot.about_command))
    application.add_handler(CommandHandler("feedback", bot.feedback_command))
    
    # –û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
    application.add_handler(
        MessageHandler(filters.TEXT & ~filters.COMMAND, bot.analyze_message)
    )
    
    # –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–Ω–æ–ø–æ–∫
    application.add_handler(CallbackQueryHandler(bot.button_callback))
    
    # –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
    logger.info("üöÄ –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π –∑–∞–ø—É—â–µ–Ω —Å GPU –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π!")
    logger.info(f"‚ö° GPU: {torch.cuda.get_device_name(0) if device.type == 'cuda' else 'CPU'}")
    logger.info(f"üß† –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏: {sum(p.numel() for p in bot.model.parameters()):,}")
    
    application.run_polling(allowed_updates=Update.ALL_TYPES)

if __name__ == "__main__":
    main()