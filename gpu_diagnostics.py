"""
–ü–û–õ–ù–ê–Ø –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –ò –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–û–ï –†–ï–®–ï–ù–ò–ï –ü–†–û–ë–õ–ï–ú –° GPU
–î–ª—è RTX 3060 Ti –∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
"""
import os
import sys
import subprocess
import platform
import ctypes
import json
from pathlib import Path

class GPUDiagnostics:
    def __init__(self):
        self.problems = []
        self.solutions = []
        self.gpu_ready = False
        
    def run_full_diagnostics(self):
        """–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏"""
        print("="*70)
        print("üîç –ü–û–õ–ù–ê–Ø –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê GPU –î–õ–Ø –ú–ê–®–ò–ù–ù–û–ì–û –û–ë–£–ß–ï–ù–ò–Ø")
        print("="*70)
        
        # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏—Å—Ç–µ–º—ã
        self.check_system()
        
        # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—Ä–∞–π–≤–µ—Ä–æ–≤
        self.check_nvidia_drivers()
        
        # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ CUDA
        self.check_cuda()
        
        # 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ Python –ø–∞–∫–µ—Ç–æ–≤
        self.check_python_packages()
        
        # 5. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
        self.check_environment()
        
        # 6. –¢–µ—Å—Ç—ã GPU
        self.test_gpu_frameworks()
        
        # 7. –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        self.print_results()
        
    def check_system(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏—Å—Ç–µ–º—ã"""
        print("\n1Ô∏è‚É£ –ü–†–û–í–ï–†–ö–ê –°–ò–°–¢–ï–ú–´")
        print("-"*50)
        
        # Windows –≤–µ—Ä—Å–∏—è
        if platform.system() != "Windows":
            self.problems.append("–û–° –Ω–µ Windows")
            self.solutions.append("–≠—Ç–∞ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è —Ç–æ–ª—å–∫–æ –¥–ª—è Windows")
            
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∞–≤ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞
        is_admin = ctypes.windll.shell32.IsUserAnAdmin()
        print(f"üñ•Ô∏è  –û–°: {platform.system()} {platform.release()}")
        print(f"üë§ –ü—Ä–∞–≤–∞ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞: {'–î–∞' if is_admin else '–ù–µ—Ç'}")
        
        if not is_admin:
            self.problems.append("–ù–µ—Ç –ø—Ä–∞–≤ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞")
            self.solutions.append("–ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∫—Ä–∏–ø—Ç –æ—Ç –∏–º–µ–Ω–∏ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞")
            
        # Python –≤–µ—Ä—Å–∏—è
        py_ver = sys.version_info
        print(f"üêç Python: {py_ver.major}.{py_ver.minor}.{py_ver.micro}")
        
        if py_ver.major == 3 and py_ver.minor == 12:
            self.problems.append("Python 3.12 –º–æ–∂–µ—Ç –∏–º–µ—Ç—å –ø—Ä–æ–±–ª–µ–º—ã —Å CUDA")
            self.solutions.append("–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è Python 3.9-3.11")
            
    def check_nvidia_drivers(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—Ä–∞–π–≤–µ—Ä–æ–≤ NVIDIA"""
        print("\n2Ô∏è‚É£ –ü–†–û–í–ï–†–ö–ê –î–†–ê–ô–í–ï–†–û–í NVIDIA")
        print("-"*50)
        
        try:
            result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)
            if result.returncode == 0:
                print("‚úÖ nvidia-smi –Ω–∞–π–¥–µ–Ω")
                
                # –ü–∞—Ä—Å–∏–º –≤—ã–≤–æ–¥ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤–µ—Ä—Å–∏–∏ –¥—Ä–∞–π–≤–µ—Ä–∞
                for line in result.stdout.split('\n'):
                    if 'Driver Version' in line:
                        driver_version = line.split('Driver Version:')[1].split()[0]
                        print(f"üìä –í–µ—Ä—Å–∏—è –¥—Ä–∞–π–≤–µ—Ä–∞: {driver_version}")
                        
                        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –≤–µ—Ä—Å–∏–∏ –¥–ª—è RTX 3060 Ti
                        if float(driver_version.split('.')[0]) < 516:
                            self.problems.append(f"–°—Ç–∞—Ä–∞—è –≤–µ—Ä—Å–∏—è –¥—Ä–∞–π–≤–µ—Ä–∞: {driver_version}")
                            self.solutions.append("–û–±–Ω–æ–≤–∏—Ç–µ –¥—Ä–∞–π–≤–µ—Ä NVIDIA –¥–æ –≤–µ—Ä—Å–∏–∏ 516.01 –∏–ª–∏ –≤—ã—à–µ")
                            
                # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ GPU
                gpu_info = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader'], 
                                        capture_output=True, text=True)
                if gpu_info.returncode == 0:
                    print(f"üéÆ GPU: {gpu_info.stdout.strip()}")
            else:
                self.problems.append("nvidia-smi –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç")
                self.solutions.append("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∏–ª–∏ –ø–µ—Ä–µ—É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –¥—Ä–∞–π–≤–µ—Ä—ã NVIDIA")
                
        except FileNotFoundError:
            self.problems.append("nvidia-smi –Ω–µ –Ω–∞–π–¥–µ–Ω")
            self.solutions.append("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –¥—Ä–∞–π–≤–µ—Ä—ã NVIDIA —Å https://www.nvidia.com/Download/index.aspx")
            
    def check_cuda(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ CUDA"""
        print("\n3Ô∏è‚É£ –ü–†–û–í–ï–†–ö–ê CUDA")
        print("-"*50)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ CUDA_PATH
        cuda_path = os.environ.get('CUDA_PATH')
        if cuda_path:
            print(f"‚úÖ CUDA_PATH: {cuda_path}")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–µ—Ä—Å–∏–∏
            version_file = Path(cuda_path) / "version.txt"
            if version_file.exists():
                with open(version_file, 'r') as f:
                    cuda_version = f.read().strip()
                    print(f"üìä CUDA –≤–µ—Ä—Å–∏—è: {cuda_version}")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ nvcc
            nvcc_path = Path(cuda_path) / "bin" / "nvcc.exe"
            if nvcc_path.exists():
                nvcc_result = subprocess.run([str(nvcc_path), '--version'], capture_output=True, text=True)
                if nvcc_result.returncode == 0:
                    print("‚úÖ nvcc –Ω–∞–π–¥–µ–Ω –∏ —Ä–∞–±–æ—Ç–∞–µ—Ç")
                else:
                    self.problems.append("nvcc –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç")
            else:
                self.problems.append("nvcc.exe –Ω–µ –Ω–∞–π–¥–µ–Ω")
                self.solutions.append("–ü–µ—Ä–µ—É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ CUDA Toolkit")
        else:
            self.problems.append("CUDA_PATH –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            self.solutions.append("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ CUDA Toolkit 11.7 –∏–ª–∏ 11.8")
            
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ cudNN
        cudnn_paths = [
            Path(cuda_path) / "bin" / "cudnn64_8.dll" if cuda_path else None,
            Path("C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.7/bin/cudnn64_8.dll"),
            Path("C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.8/bin/cudnn64_8.dll"),
        ]
        
        cudnn_found = False
        for path in cudnn_paths:
            if path and path.exists():
                print(f"‚úÖ cuDNN –Ω–∞–π–¥–µ–Ω: {path}")
                cudnn_found = True
                break
                
        if not cudnn_found:
            self.problems.append("cuDNN –Ω–µ –Ω–∞–π–¥–µ–Ω")
            self.solutions.append("–°–∫–∞—á–∞–π—Ç–µ cuDNN —Å https://developer.nvidia.com/cudnn")
            
    def check_python_packages(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ Python –ø–∞–∫–µ—Ç–æ–≤"""
        print("\n4Ô∏è‚É£ –ü–†–û–í–ï–†–ö–ê PYTHON –ü–ê–ö–ï–¢–û–í")
        print("-"*50)
        
        # TensorFlow
        try:
            import tensorflow as tf
            print(f"‚úÖ TensorFlow: {tf.__version__}")
            print(f"   CUDA –ø–æ—Å—Ç—Ä–æ–µ–Ω: {tf.test.is_built_with_cuda()}")
            print(f"   GPU –¥–æ—Å—Ç—É–ø–Ω—ã: {len(tf.config.list_physical_devices('GPU'))}")
            
            if not tf.test.is_built_with_cuda():
                self.problems.append("TensorFlow —Å–æ–±—Ä–∞–Ω –±–µ–∑ CUDA")
                self.solutions.append("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ tensorflow-gpu –∏–ª–∏ tensorflow>=2.10.0")
                
        except ImportError:
            self.problems.append("TensorFlow –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            self.solutions.append("pip install tensorflow==2.10.0")
            
        # PyTorch
        try:
            import torch
            print(f"‚úÖ PyTorch: {torch.__version__}")
            print(f"   CUDA –¥–æ—Å—Ç—É–ø–Ω–∞: {torch.cuda.is_available()}")
            print(f"   CUDA –≤–µ—Ä—Å–∏—è: {torch.version.cuda}")
            
            if not torch.cuda.is_available():
                self.problems.append("PyTorch –Ω–µ –≤–∏–¥–∏—Ç CUDA")
                self.solutions.append("pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118")
                
        except ImportError:
            print("‚ö†Ô∏è  PyTorch –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)")
            
    def check_environment(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è"""
        print("\n5Ô∏è‚É£ –ü–†–û–í–ï–†–ö–ê –ü–ï–†–ï–ú–ï–ù–ù–´–• –û–ö–†–£–ñ–ï–ù–ò–Ø")
        print("-"*50)
        
        important_vars = {
            'CUDA_PATH': '–ü—É—Ç—å –∫ CUDA Toolkit',
            'CUDNN_PATH': '–ü—É—Ç—å –∫ cuDNN (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)',
            'PATH': '–î–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å CUDA/bin'
        }
        
        for var, desc in important_vars.items():
            value = os.environ.get(var, '')
            if var == 'PATH':
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ CUDA –≤ PATH
                cuda_in_path = any('cuda' in p.lower() for p in value.split(';'))
                print(f"{'‚úÖ' if cuda_in_path else '‚ö†Ô∏è '} {var}: {'CUDA –Ω–∞–π–¥–µ–Ω' if cuda_in_path else 'CUDA –Ω–µ –Ω–∞–π–¥–µ–Ω'} –≤ PATH")
                
                if not cuda_in_path:
                    self.problems.append("CUDA/bin –Ω–µ –≤ PATH")
                    self.solutions.append("–î–æ–±–∞–≤—å—Ç–µ C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.X\\bin –≤ PATH")
            else:
                print(f"{'‚úÖ' if value else '‚ùå'} {var}: {value if value else '–ù–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω'}")
                
    def test_gpu_frameworks(self):
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–æ–≤"""
        print("\n6Ô∏è‚É£ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï GPU")
        print("-"*50)
        
        # TensorFlow —Ç–µ—Å—Ç
        print("\nüî∑ TensorFlow GPU —Ç–µ—Å—Ç:")
        tf_test = """
import tensorflow as tf
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

gpus = tf.config.list_physical_devices('GPU')
if gpus:
    print(f"‚úÖ TensorFlow –≤–∏–¥–∏—Ç {len(gpus)} GPU")
    for gpu in gpus:
        print(f"   {gpu}")
    # –ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç
    with tf.device('/GPU:0'):
        a = tf.constant([[1.0, 2.0], [3.0, 4.0]])
        b = tf.constant([[5.0, 6.0], [7.0, 8.0]])
        c = tf.matmul(a, b)
    print("‚úÖ –í—ã—á–∏—Å–ª–µ–Ω–∏—è –Ω–∞ GPU —Ä–∞–±–æ—Ç–∞—é—Ç")
else:
    print("‚ùå TensorFlow –Ω–µ –≤–∏–¥–∏—Ç GPU")
"""
        try:
            exec(tf_test)
            self.gpu_ready = True
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ TensorFlow: {str(e)}")
            
        # PyTorch —Ç–µ—Å—Ç
        print("\nüî∂ PyTorch GPU —Ç–µ—Å—Ç:")
        pytorch_test = """
import torch

if torch.cuda.is_available():
    print(f"‚úÖ PyTorch –≤–∏–¥–∏—Ç GPU: {torch.cuda.get_device_name(0)}")
    print(f"   –ü–∞–º—è—Ç—å: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    # –ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç
    a = torch.randn(100, 100).cuda()
    b = torch.randn(100, 100).cuda()
    c = torch.matmul(a, b)
    print("‚úÖ –í—ã—á–∏—Å–ª–µ–Ω–∏—è –Ω–∞ GPU —Ä–∞–±–æ—Ç–∞—é—Ç")
else:
    print("‚ùå PyTorch –Ω–µ –≤–∏–¥–∏—Ç GPU")
"""
        try:
            exec(pytorch_test)
            self.gpu_ready = True
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ PyTorch: {str(e)}")
            
    def print_results(self):
        """–í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏"""
        print("\n" + "="*70)
        print("üìã –†–ï–ó–£–õ–¨–¢–ê–¢–´ –î–ò–ê–ì–ù–û–°–¢–ò–ö–ò")
        print("="*70)
        
        if not self.problems:
            print("\n‚úÖ –í–°–ï –û–¢–õ–ò–ß–ù–û! GPU –ì–û–¢–û–í –ö –†–ê–ë–û–¢–ï!")
            print("\nüöÄ –ú–æ–∂–µ—Ç–µ –∑–∞–ø—É—Å–∫–∞—Ç—å –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏!")
        else:
            print(f"\n‚ùå –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ø—Ä–æ–±–ª–µ–º: {len(self.problems)}")
            print("\nüîß –ü–†–û–ë–õ–ï–ú–´ –ò –†–ï–®–ï–ù–ò–Ø:")
            print("-"*50)
            
            for i, (problem, solution) in enumerate(zip(self.problems, self.solutions), 1):
                print(f"\n{i}. ‚ùå –ü—Ä–æ–±–ª–µ–º–∞: {problem}")
                print(f"   üí° –†–µ—à–µ–Ω–∏–µ: {solution}")
                
            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è
            print("\n" + "="*70)
            print("üîß –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø")
            print("="*70)
            
            self.auto_fix()
            
    def auto_fix(self):
        """–ü–æ–ø—ã—Ç–∫–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º"""
        print("\nü§ñ –ü—ã—Ç–∞–µ–º—Å—è –∏—Å–ø—Ä–∞–≤–∏—Ç—å –ø—Ä–æ–±–ª–µ–º—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏...")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Å–∫—Ä–∏–ø—Ç–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏
        fix_script = """@echo off
echo ====================================
echo –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï GPU
echo ====================================
echo.

"""
        
        if "TensorFlow –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω" in str(self.problems):
            fix_script += """
echo –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º TensorFlow GPU...
python -m pip install tensorflow==2.10.0 --upgrade --force-reinstall
echo.
"""
        
        if "PyTorch –Ω–µ –≤–∏–¥–∏—Ç CUDA" in str(self.problems):
            fix_script += """
echo –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º PyTorch —Å CUDA...
python -m pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
echo.
"""
        
        if "CUDA Toolkit" in str(self.solutions):
            fix_script += """
echo.
echo CUDA Toolkit –Ω—É–∂–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≤—Ä—É—á–Ω—É—é:
echo 1. –°–∫–∞—á–∞–π—Ç–µ CUDA 11.8: https://developer.nvidia.com/cuda-11-8-0-download-archive
echo 2. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —É—Å—Ç–∞–Ω–æ–≤—â–∏–∫
echo 3. –í—ã–±–µ—Ä–∏—Ç–µ Custom Installation
echo 4. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ —Ç–æ–ª—å–∫–æ CUDA Toolkit
echo.
pause
"""
        
        fix_script += """
echo.
echo –ì–æ—Ç–æ–≤–æ! –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É.
pause
"""
        
        with open("fix_gpu_problems.bat", "w") as f:
            f.write(fix_script)
            
        print("‚úÖ –°–æ–∑–¥–∞–Ω fix_gpu_problems.bat")
        print("üîÑ –ó–∞–ø—É—Å—Ç–∏—Ç–µ –µ–≥–æ –æ—Ç –∏–º–µ–Ω–∏ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞!")

# –ó–∞–ø—É—Å–∫ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
if __name__ == "__main__":
    diagnostics = GPUDiagnostics()
    diagnostics.run_full_diagnostics()
    
    print("\n" + "="*70)
    print("üí° –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –°–û–í–ï–¢–´:")
    print("="*70)
    print("\n1. –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –ø–æ–º–æ–≥–∞–µ—Ç - –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç–µ –∫–æ–º–ø—å—é—Ç–µ—Ä")
    print("2. –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ RTX 3060 Ti –ø—Ä–∞–≤–∏–ª—å–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –≤ —Å–ª–æ—Ç PCIe")
    print("3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–∏—Ç–∞–Ω–∏–µ GPU (—Ç—Ä–µ–±—É–µ—Ç—Å—è 8-pin –∫–æ–Ω–Ω–µ–∫—Ç–æ—Ä)")
    print("4. –û—Ç–∫–ª—é—á–∏—Ç–µ –≤—Å—Ç—Ä–æ–µ–Ω–Ω—É—é –≥—Ä–∞—Ñ–∏–∫—É –≤ BIOS –µ—Å–ª–∏ –µ—Å—Ç—å")
    print("5. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø–æ—Å–ª–µ–¥–Ω–∏–µ –¥—Ä–∞–π–≤–µ—Ä—ã NVIDIA Game Ready –∏–ª–∏ Studio")